digit
neurons [ 10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170 180
 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360
 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540
 550  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170
 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350
 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530
 540 550  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160
 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340
 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520
 530 540 550]
layers [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]
accuracies [0.6446 0.8371 0.8491 0.8636 0.8685 0.8708 0.8618 0.869  0.8747 0.8679
 0.8665 0.873  0.8727 0.8801 0.8788 0.8708 0.8804 0.879  0.8825 0.8804
 0.8767 0.8787 0.8836 0.8815 0.8802 0.8776 0.8781 0.8786 0.8816 0.8827
 0.8831 0.8779 0.8829 0.88   0.8798 0.8824 0.8812 0.883  0.8826 0.8845
 0.8832 0.8852 0.8829 0.8831 0.8815 0.8831 0.8854 0.8844 0.8827 0.883
 0.8872 0.883  0.8852 0.8838 0.8875 0.5379 0.6976 0.7382 0.8083 0.8515
 0.8737 0.8691 0.8677 0.8781 0.8832 0.8755 0.8711 0.8758 0.8751 0.8807
 0.8787 0.885  0.8811 0.8873 0.8862 0.8871 0.8849 0.8833 0.8851 0.8868
 0.8868 0.8888 0.8898 0.8868 0.8855 0.8901 0.888  0.8838 0.8924 0.8919
 0.8885 0.8934 0.8881 0.8927 0.8881 0.8916 0.8913 0.8873 0.8919 0.8944
 0.8952 0.8915 0.8923 0.8966 0.8957 0.8943 0.8953 0.8939 0.891  0.8954
 0.2905 0.5253 0.6058 0.722  0.7997 0.8007 0.8461 0.8617 0.8666 0.8796
 0.8542 0.8799 0.8634 0.876  0.869  0.876  0.8797 0.888  0.8861 0.8821
 0.8788 0.8853 0.8789 0.8881 0.8831 0.8931 0.8815 0.8846 0.8894 0.8899
 0.8938 0.8884 0.8892 0.8919 0.889  0.8922 0.8946 0.8927 0.8948 0.8936
 0.8935 0.8953 0.8954 0.9    0.8964 0.891  0.8968 0.8968 0.8973 0.8973
 0.898  0.8953 0.8989 0.8983 0.9003]
runtime 11629.182165384293

fashion
layers [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 
2 2 2 2 2 2 2 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 
3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]
accuracies [0.5265 0.7097 0.7574 0.7493 0.7714 0.7649 0.7656 0.7693 0.7689 0.7761
 0.7808 0.7824 0.7799 0.7796 0.7793 0.7742 0.7858 0.7818 0.7818 0.7818
 0.7809 0.7858 0.7907 0.7803 0.7816 0.7834 0.7839 0.7886 0.7867 0.7869
 0.7854 0.7897 0.7833 0.7843 0.7883 0.7904 0.7843 0.7848 0.7879 0.7897
 0.7924 0.7872 0.7843 0.7861 0.7895 0.7946 0.7967 0.7958 0.791  0.7856
 0.7933 0.7897 0.7931 0.7941 0.7916 0.6073 0.7264 0.713  0.7169 0.7444
 0.7768 0.7641 0.7791 0.7749 0.7755 0.7773 0.7869 0.7781 0.7856 0.788
 0.7869 0.7875 0.7819 0.7869 0.7869 0.787  0.7942 0.788  0.7913 0.793
 0.7945 0.7915 0.7936 0.7994 0.794  0.7981 0.7972 0.7944 0.7911 0.7974
 0.7976 0.7951 0.7969 0.7998 0.7986 0.8009 0.7994 0.8004 0.7959 0.8006
 0.8023 0.8019 0.797  0.8026 0.8009 0.7997 0.8027 0.8068 0.8042 0.8035
 0.3363 0.662  0.6694 0.7038 0.7506 0.7417 0.7618 0.7817 0.7692 0.7826
 0.7821 0.7802 0.78   0.786  0.7885 0.7788 0.7781 0.7893 0.7877 0.792
 0.7877 0.7943 0.7892 0.7926 0.7878 0.7975 0.7961 0.7908 0.7986 0.7923
 0.7962 0.8031 0.8016 0.7992 0.8004 0.797  0.8047 0.7962 0.8056 0.7929
 0.7985 0.8004 0.7998 0.8014 0.8026 0.8013 0.8003 0.805  0.8017 0.8027
 0.802  0.8021 0.8034 0.8017 0.8047]
runtime 12542.069205284119